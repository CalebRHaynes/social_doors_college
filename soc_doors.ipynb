{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "soc_doors.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1QeqfoMFVQzmk9teKDDTSymLBFLojxdL6",
      "authorship_tag": "ABX9TyNb4jqC7liRr+YIkcqm1lib",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CalebRHaynes/social_doors_college/blob/master/soc_doors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq2i83IRf270"
      },
      "source": [
        "# Import Neuroimaging Data and Behavioral Files\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClUw_KN0gKrP",
        "outputId": "798d2632-3395-430c-8acf-2025020f39a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import glob \n",
        "import pandas as pd\n",
        "!ls"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG8r9ZF8gPfR",
        "outputId": "67da318e-6859-43f6-b79b-d4ca98d0207a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "class Subject:\n",
        "  \n",
        "  def __init__(self, subnum):\n",
        "    self.subnum = subnum\n",
        "\n",
        "  def path_get(self, path):\n",
        "  \n",
        "    root_dir = 'drive/My Drive/social_doors_college/'\n",
        "\n",
        "    mriqc_data = root_dir + f'mriqc/reports/sub-{self.subnum}_task*'\n",
        "    #functional_data = \n",
        "    #T1 =\n",
        "    \n",
        "    beh_timing_files = glob.glob(root_dir + f'/behavior/EVfiles/{self.subnum}/*/*')\n",
        "    \n",
        "    #filetype- excel\n",
        "    raw_behavioral = glob.glob(f'drive/My Drive/social_doors_college/behavior/raw/s{self.subnum}/*/*.xlsx')\n",
        "    \n",
        "    if path == 'L1':\n",
        "      req = glob.glob(f'/content/drive/My Drive/social_doors_college/lowerLv_results/sub-{self.subnum}/L1*.feat')\n",
        "    elif path == 'L2':\n",
        "      req = glob.glob(f'/content/drive/My Drive/social_doors_college/lowerLv_results/sub-{self.subnum}/L2*.gfeat')\n",
        "    return req\n",
        "\n",
        "  def get_l1_files(self):\n",
        "    return self.path_get('L1')\n",
        "  \n",
        "  def get_l2_files(self):\n",
        "    return self.path_get('L2')\n",
        "\n",
        "  def get_rvst(self):\n",
        "    df = pd.read_csv('/content/drive/My Drive/social_doors_college/code/nm_rvst.csv')\n",
        "    print(df.loc[df['subno'] == self.subnum])\n",
        "\n",
        "p1 = Subject(3836).get_rvst()\n",
        "\n"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   subno        RVST\n",
            "0   3836  116.035119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEQMmAPGhFPO",
        "outputId": "12058b40-4da0-480f-8cfb-f41c7e91b15e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "class Dataset:\n",
        "  def __init__(self, sublist):\n",
        "    self.sublist = sublist\n",
        "    pass\n",
        "\n",
        "  #fmriprepdir \n",
        "  \n",
        "  \n",
        "  #sub_list = '/content/drive/My Drive/social_doors_college/code/sub_list.txt'\n",
        "  \n",
        "  def get_sublist(self):\n",
        "    with open(self.sublist, \"r\") as file:\n",
        "      lines = file.readlines()\n",
        "    \n",
        "    subject_list = []\n",
        "      \n",
        "    for s in lines:\n",
        "      as_list = s.split(\", \")\n",
        "      subject_list.append(as_list[0].replace(\"\\n\", \"\"))\n",
        "\n",
        "    file.close()\n",
        "      \n",
        "    return subject_list\n",
        "\n",
        "  #masks\n",
        "  \n",
        "\n",
        "  def make_data_frame(self):\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "full_sub_list = Dataset('/content/drive/My Drive/social_doors_college/code/sub_list.txt').get_sublist()\n",
        "print(full_sub_list)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Subjects', 'sub-3836', 'sub-3845', 'sub-3846', 'sub-3847', 'sub-3849', 'sub-3851', 'sub-3852', 'sub-3855', 'sub-3864', 'sub-3865', 'sub-3871', 'sub-3877', 'sub-3883', 'sub-3886', 'sub-3887', 'sub-3889', 'sub-3890', 'sub-3891', 'sub-3892', 'sub-3893', 'sub-3895', 'sub-3910', 'sub-3912', 'sub-3920', 'sub-3967', 'sub-3992', 'sub-4017', 'sub-4018', 'sub-4019', 'sub-4020']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBDZH5tOjaeK"
      },
      "source": [
        "# Onset Extraction, EV File Generate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SLyRIyxky60",
        "outputId": "ba9b3152-2c36-44f1-e76b-3662fde09e57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import defaultdict\n",
        "import csv\n",
        "import json\n",
        "!pwd"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEMHqIaXoyKw"
      },
      "source": [
        "#EV File (3 col) Generation\n",
        "def event_writer(event_type, df_series, duration, block_type):\n",
        "    '''\n",
        "    Funciton takes a string, pandas series, and a float/int\n",
        "    This function \n",
        "    1. Converts ms in series to s, and makes dataframe obj\n",
        "    2. Duration is appended as a 'default value' column\n",
        "    3. Makes column of ones (expected by fsl) and adds to df\n",
        "    4. Writes out to csv with index and header turned off\n",
        "    '''\n",
        "    df = (df_series/1000).to_frame()\n",
        "    df['duration'] = duration\n",
        "    df['mag'] = 1.0\n",
        "    df.to_csv(f'../behavior/EVfiles/{sub}/{condition_type}/run-0{run}_{block_type}_{event_type}.txt', index = False, header = False, sep = '\\t')\n",
        "    \n",
        "\n",
        "def extract_fd_vals(json_file):\n",
        "    f = open(json_file)\n",
        "    data = json.load(f)\n",
        "    fd_data = data['fd_mean'] \n",
        "    f.close() \n",
        "    return fd_data"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dcb_MiZgpfOL"
      },
      "source": [
        "#make a list for logging an intermediate file\n",
        "\n",
        "interm = {}\n",
        "\n",
        "'''\n",
        "Split excel files into 4, convert to 3 'colmumn file' within sub folders\n",
        "\n",
        "iterate over each excel file - 2 per person: social, nonsocial\n",
        "\n",
        "2 blocks within each run\n",
        "\n",
        "4 EVs in question: instruction, correct, incorect and decision\n",
        "\n",
        "'''\n",
        "\n",
        "for excel in glob.glob('../behavior/raw/s*/*/*.xlsx')[:]:\n",
        "    \n",
        "    #get sub number from filename\n",
        "    sub = excel[17:21]\n",
        "    print(sub)\n",
        "    #load into pandas dataframe \n",
        "    df = pd.read_excel(excel, header = 1)\n",
        "    \n",
        "\n",
        "    #define block list\n",
        "    split_df = np.array_split(df, 4)\n",
        "    \n",
        "    \n",
        "    #iterate over blocks in excel file\n",
        "    for block in split_df:\n",
        "        '''\n",
        "        get the columns for scanner offset, decision onsets, and feedback onsets \n",
        "        This uses the index of columns, which switches between the social and non-social files\n",
        "        \n",
        "        ''' \n",
        "        condition_type = 'social' if 'Social' in df.iloc[0][0] else 'doors'\n",
        "        \n",
        "        \n",
        "        block_type = block['Procedure[Trial]'].iloc[0]\n",
        "        \n",
        "        block_type = 'positive' if ('Prize' in block_type) or ('Like' in block_type) else 'negative'\n",
        "        \n",
        "        \n",
        "        \n",
        "        if condition_type == 'social':\n",
        "            offset_value = block.iloc[1, 56]\n",
        "            decision_onsets = block.iloc[:, 82].dropna()  #get rid of nans  when possible\n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "        \n",
        "        else: #nonsocial\n",
        "            offset_value = block.iloc[1, 40]\n",
        "            decision_onsets = block.iloc[:, 51].dropna()\n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "        #get decision onsets where R or L\n",
        "        \n",
        "        \n",
        "        #print(decision_onsets, responses)\n",
        "         \n",
        "        \n",
        "        all_cols = block.columns.tolist()\n",
        "        for i in all_cols:\n",
        "            if '.RESP' in i and ('Faces' in i or 'Doors' in i):\n",
        "                response_column = i\n",
        "            else:\n",
        "                pass\n",
        "        \n",
        "        \n",
        "        response_b = block.loc[block[response_column].eq('b')]\n",
        "        response_g = block.loc[block[response_column].eq('g')]\n",
        "        \n",
        "        \n",
        "    \n",
        "        \n",
        "        \n",
        "        if condition_type == 'social':\n",
        "            response_b_onsets = response_b.iloc[:, 82].dropna()\n",
        "            response_g_onsets = response_g.iloc[:, 82].dropna()#get rid of nans  when possible\n",
        "        else: #nonsocial\n",
        "            response_b_onsets = response_b.iloc[:, 51].dropna()\n",
        "            response_g_onsets = response_g.iloc[:, 51].dropna()\n",
        "        \n",
        "        #alternate,cleaner method for above\n",
        "        #offset_value = block.filter(regex='ScannerTrigger*..OffsetTime', axis = 1).iloc[0].iloc[0]\n",
        "        \n",
        "        #get feedback onsets for correct and incorrect\n",
        "        correct_onsets = block.loc[block['TrialType'] =='win', 'Outcome.OnsetTime']\n",
        "        incorrect_onsets = block.loc[block['TrialType'] =='loss', 'Outcome.OnsetTime']\n",
        "        \n",
        "        #assign run based on column named \"Block\"\n",
        "        run = block['Block'].iloc[0] \n",
        "        \n",
        "        #assign a or b on column named \"Block Number\" \n",
        "        if block['BlockNumber'].iloc[0] == 1 :\n",
        "            block_a_b = 'a'\n",
        "        elif block['BlockNumber'].iloc[0] == 2:\n",
        "            block_a_b = 'b' \n",
        "        else:\n",
        "            print(\"Error\")       \n",
        "        \n",
        "        \n",
        "        \n",
        "        #add fdmean values to log \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        #instruction type, as a string, is determined within block \n",
        "        instruction_type = block['Procedure[Trial]'].iloc[0][:-4] + 's.OnsetTime'\n",
        "         \n",
        "        #make scanner trigger adjustements\n",
        "        \n",
        "        adjusted_decision_onsets = decision_onsets.subtract(offset_value)\n",
        "        \n",
        "        adjusted_response_b_onsets = response_b_onsets.subtract(offset_value)\n",
        "        adjusted_response_g_onsets = response_g_onsets.subtract(offset_value)\n",
        "        \n",
        "        adjusted_correct_onsets = correct_onsets.subtract(offset_value)\n",
        "        adjusted_incorrect_onsets = incorrect_onsets.subtract(offset_value)\n",
        "           \n",
        "        #use first and last events to get experiment time \n",
        "        unadj_start = block[instruction_type].iloc[0]\n",
        "        unadj_end = block['ITI.OffsetTime'].iloc[-1]\n",
        "        \n",
        "        block_start = (unadj_start - offset_value)\n",
        "        block_end = (unadj_end - offset_value)\n",
        "        dur = unadj_end - unadj_start\n",
        "           \n",
        "        #TR is 2.1 s\n",
        "        trs = dur/2100\n",
        "        \n",
        "            \n",
        "        '''\n",
        "        B trials need to be given a new 'zero point'\n",
        "        '''\n",
        "        \n",
        "        #print(block_a_b, adjusted_response_b_onsets)\n",
        "        \n",
        "        #reset b runs to block onsets, additional TR correction \n",
        "        if block_a_b == 'b':\n",
        "            #print(True)\n",
        "            #check for negatives\n",
        "            #data correspond to which part of run\n",
        "            \n",
        "            #rename variables here, double check values\n",
        "            \n",
        "            adjusted_decision_onsets = adjusted_decision_onsets.subtract(block_start)\n",
        "            \n",
        "            adjusted_response_b_onsets = adjusted_response_b_onsets.subtract(block_start)\n",
        "            adjusted_response_g_onsets = adjusted_response_g_onsets.subtract(block_start)\n",
        "            \n",
        "            adjusted_correct_onsets = adjusted_correct_onsets.subtract(block_start)\n",
        "            adjusted_incorrect_onsets = adjusted_incorrect_onsets.subtract(block_start)\n",
        "            \n",
        "        else:\n",
        "            pass\n",
        "    \n",
        "        #print(adjusted_response_b_onsets)\n",
        "        \n",
        "        instruct_list = [0., 5., 1.]\n",
        "        \n",
        "        #write EVs to file\n",
        "        #event_writer('correct', adjusted_correct_onsets, 1., condition_type)\n",
        "        #event_writer('incorrect', adjusted_incorrect_onsets, 1., condition_type)\n",
        "        #event_writer('decision', adjusted_decision_onsets, 3., condition_type)\n",
        "        \n",
        "        #event_writer('Rdecision', adjusted_response_b_onsets, 3., block_a_b)\n",
        "        #event_writer('Ldecision', adjusted_response_g_onsets, 3., block_a_b)\n",
        "      \n",
        "        #with open(f'../behavior/EVfiles/{sub}/{condition_type}/run-0{run}_{block_type}_instruction.txt', 'w', newline='') as csvfile:\n",
        "        #        writer = csv.writer(csvfile, delimiter='\\t',\n",
        "        #                        quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "        #        writer.writerow(instruct_list)\n",
        "\n",
        "        #Add Block Info To Log\n",
        "        #d1 = {sub + f'_{condition_type}_'+'_run_' + str(run) + '_block_' + block_a_b: [start, stop, block_length, block_a_b, condition_type, run, trs, block_type]}\n",
        "        #interm.update(d1)\n",
        "\n",
        "        #slicing the block out of the NIFTI  file\n",
        "        \n",
        "        if trs > 66:\n",
        "            block_length = 'long'\n",
        "            stop = 66\n",
        "            if block_a_b == 'a':\n",
        "                start = 0\n",
        "            elif block_a_b == 'b' and block_length == 'long':\n",
        "                start = 64\n",
        "        elif trs < 65:\n",
        "            block_length = 'short'\n",
        "            stop = 64\n",
        "            if block_a_b == 'a':\n",
        "                start = 0\n",
        "            elif block_a_b == 'b' and block_length == 'short':\n",
        "                start = 66\n",
        "    \n",
        "\n",
        "        d1 = {sub + f'_{condition_type}_'+'_run_' + str(run) + '_block_' + block_a_b: [start, stop, block_length, block_a_b, condition_type, run, trs, block_type]}\n",
        "        interm.update(d1)\n",
        "\n",
        "        \n",
        "        #if condition_type == 'social':\n",
        "        #    infile = f'../bids/sub-{sub}/func/sub-{sub}_task-srSocial_run-0{run}_bold.nii.gz' \n",
        "        #    outfile = f'../bids/sub-{sub}/func/sub-{sub}_task-srSocial{block_a_b}_run-0{run}_bold.nii.gz'\n",
        "        #    !fslroi $infile $outfile $start $stop \n",
        "        #else:\n",
        "        #    infile = f'../bids/sub-{sub}/func/sub-{sub}_task-srDoors_run-0{run}_bold.nii.gz' \n",
        "        #    outfile = f'../bids/sub-{sub}/func/sub-{sub}_task-srDoors{block_a_b}_run-0{run}_bold.nii.gz'\n",
        "        #    !fslroi $infile $outfile $start $stop "
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt-XCu6Xp-kd"
      },
      "source": [
        "#Write Log Out\n",
        "#df = pd.DataFrame(interm).transpose()\n",
        "#df.columns = ['Starting Volume', 'Length in Volumes', 'Long or Short', 'Block Type', 'Condition', 'Run Number', 'N Volumes', 'Instruction Valence']\n",
        "#df.to_csv('test_output.csv')"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0V6orpdjkQk"
      },
      "source": [
        "# Level One Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuSY_kBZwiGG"
      },
      "source": [
        "import glob\n",
        "from csv import reader\n",
        "\n",
        "\n",
        "for i in glob.glob('../behavior/EVfiles/*'):\n",
        "    sub_number = i[20:24]\n",
        "    print(sub_number)\n",
        "    with open('test_output.csv', 'r') as read_obj:\n",
        "        csv_reader = reader(read_obj)\n",
        "        # Iterate over each row in the csv using reader object\n",
        "        for row in csv_reader:\n",
        "            if sub_number == row[0][:4]:\n",
        "                trial_type = row[0][-1:]\n",
        "                nvols = row[2]\n",
        "                condition = row[0][5:11]\n",
        "                condition = condition.replace(\"_\", \"\").capitalize()\n",
        "                print(trial_type, nvols, condition)\n",
        "                #!./models/L1_task-sr$condition$trial_type\\_\\model-01.sh $sub_number 2 0 6 $nvols\n",
        "                #!./models/L1_task-sr$condition$trial_type\\_\\model-01.sh $sub_number 1 0 6 $nvols\n",
        "        read_obj.close()"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt-0efENwkUh"
      },
      "source": [
        "# L1 Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDRH6XTtwwcw",
        "outputId": "cc291980-ba9c-4041-e10d-7ead98ae95c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_file = pd.read_csv('/content/drive/My Drive/social_doors_college/code/test_output.csv')\n",
        "\n",
        "print(test_file)\n",
        "\n",
        "import glob\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "\n",
        "raw_data = glob.glob(\"../behavior/raw/s*\")\n",
        "EV_files = glob.glob('../behavior/EVfiles/*/*/*')\n",
        "test_file = pd.read_csv('test_output.csv')\n",
        "nii_root = '../bids/s*/func/*bold.nii.gz'\n",
        "\n",
        "\n",
        "\n",
        "for file in test_file.iterrows():\n",
        "\tfile_type = file[1][0]\n",
        "\t#get file parameters \n",
        "\trun = file[1][6]\n",
        "\tblock_letter = file_type[-1]\n",
        "\tsub = file_type[0:4]\n",
        "\t#expected_start = file[1][1]\n",
        "\texpected_length = file[1][2]\n",
        "\tcondition = file[1][5]\n",
        "\tif condition == 'doors':\n",
        "\t\tsoc_doors = f'Doors{block_letter}'\n",
        "\telif condition == 'social':\n",
        "\t\tsoc_doors = f'Social{block_letter}'\n",
        "\telse:\n",
        "\t\tprint('error')\n",
        "\t\n",
        "\ttrs = file[1][7]\n",
        "\tif trs > 65:\n",
        "\t\tslices = 66\n",
        "\telif trs <= 65:\n",
        "\t\tslices = 64\n",
        "\tprint(sub, run, block_letter, trs, slices == expected_length, slices, expected_length)\n",
        "\t#nii\n",
        "\tnii = f\"sub-{sub}_task-sr{soc_doors}_run-0{run}_bold.nii.gz\"\n",
        "\tnii_path = f'../bids/sub-{sub}/func/' + nii\n",
        "\tmri = nib.load(nii_path)\n",
        "\tprint(mri.shape[3] == expected_length)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                     Unnamed: 0  Starting Volume  ...  N Volumes Instruction Valence\n",
            "0     3847_doors__run_1_block_a                0  ...  66.333333            positive\n",
            "1     3847_doors__run_1_block_b               66  ...  63.333333            negative\n",
            "2     3847_doors__run_2_block_a                0  ...  66.333333            negative\n",
            "3     3847_doors__run_2_block_b               66  ...  63.333333            positive\n",
            "4    3847_social__run_1_block_a                0  ...  66.333333            positive\n",
            "..                          ...              ...  ...        ...                 ...\n",
            "235   3890_doors__run_2_block_b               66  ...  63.333333            positive\n",
            "236  3890_social__run_1_block_a                0  ...  66.333333            positive\n",
            "237  3890_social__run_1_block_b               66  ...  63.333333            negative\n",
            "238  3890_social__run_2_block_a                0  ...  66.333333            negative\n",
            "239  3890_social__run_2_block_b               66  ...  63.333333            positive\n",
            "\n",
            "[240 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g69NMHNhxAod"
      },
      "source": [
        "Example Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuhAxaJUkZbE"
      },
      "source": [
        "# Level Two Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-UIpQFTwxj1"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statistics import mean\n",
        "import glob"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JonNHwoJ0N-Z"
      },
      "source": [
        "def extract_fd_vals(json_file):\n",
        "    f = open(json_file)\n",
        "    data = json.load(f)\n",
        "    fd_data = data['fd_mean'] \n",
        "    f.close() \n",
        "    return fd_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh6lG9np0Q3u"
      },
      "source": [
        "def mean_fd_val(sub):\n",
        "    fd_list = []\n",
        "    for json_file in glob.glob(f'../derivatives/mriqc/derivatives/sub-{sub}*_bold.json'):\n",
        "        fd_list.append(extract_fd_vals(json_file))\n",
        "    return np.mean(fd_list)\n",
        "\n",
        "def trial_fd_val(sub, run, condition, block):\n",
        "    y = glob.glob(f'../derivatives/mriqc/derivatives/sub-{subnum}_task-sr{condition}{block}_run-0{run}_bold.json')\n",
        "    #print(sub)\n",
        "    return  extract_fd_vals(y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGbNwocH0RMM"
      },
      "source": [
        "test_file_ordering = []\n",
        "    \n",
        "for row in test_file.iterrows():\n",
        "    run = row[1][6]\n",
        "    subnum = row[1][0][:4]\n",
        "    condition = row[1][5]\n",
        "    condition = condition.capitalize()\n",
        "    valence = row[1][8]\n",
        "    block = row[1][4]\n",
        "    \n",
        "    mean_fd_sub = mean_fd_val(subnum)\n",
        "    \n",
        "    mean_fd_run = trial_fd_val(subnum, run, condition, block)\n",
        "    \n",
        "    fd = (mean_fd_run - mean_fd_sub)\n",
        "    \n",
        "    test_file_ordering.append([subnum, f\"L1_task-sr{condition}{block}_model-01_type-act_run-0{run}_sm-6_variant-dctAROMAnonaggr.feat\", valence, fd])\n",
        "            \n",
        "    df = pd.DataFrame(data = test_file_ordering, columns = ['subject', 'L1', 'inst. valence', 'demeaned fd'])\n",
        "\n",
        "    \n",
        "    \n",
        "per_sub = np.array_split(df, 30)\n",
        "\n",
        "for i in per_sub:\n",
        "    sub = i.iloc[0][0]\n",
        "    \n",
        "    \n",
        "    sorted_vals = i.sort_values(by = 'inst. valence')\n",
        "    \n",
        "    l1_models = sorted_vals.iloc[0:, 1].tolist()\n",
        "    l1_command = \" \".join([j for j in l1_models])\n",
        "    print(sub, l1_command)\n",
        "    \n",
        "    sorted_vals = i.sort_values(by = 'inst. valence')\n",
        "    fd_list = sorted_vals.iloc[0:, 3].to_list()\n",
        "    fd_command = \" \".join([str(j) for j in fd_list])\n",
        "    print(sub, len(l1_models) == 8)\n",
        "\n",
        "    \n",
        "    #!echo ./models/L2_combine_socialDoors.sh $sub  $l1_command $fd_command"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAAvRsBAwrk9"
      },
      "source": [
        "# L2 Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hw1CY6Ypu4A"
      },
      "source": [
        ""
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY_YHFWckb8G"
      },
      "source": [
        "# Group Level Mixed Effects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WRaaKLSpvUE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao9vifM5rJqz"
      },
      "source": [
        "# Group Level Descriptive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJWHCFEQpvvl",
        "outputId": "34cada02-c1e1-4bed-8f2c-4b7e9feb519f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(Dataset.show())"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class '__main__.Dataset'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QndnpA8x17oK"
      },
      "source": [
        "# Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXELDIM92QsQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2QadsiN2Q3g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK2wYn6k2Q-k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}